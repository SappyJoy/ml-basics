{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "468a73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d24e1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Загрузка данных\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217ba410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
      "0    0_0          0                   0       -0.75853       -0.63435   \n",
      "1    0_1          0                   1       -0.75853       -0.63434   \n",
      "2    0_2          0                   2       -0.75853       -0.63435   \n",
      "3    0_3          0                   3       -0.75852       -0.63436   \n",
      "4    0_4          0                   4       -0.75852       -0.63435   \n",
      "\n",
      "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
      "0       -0.10488       -0.10597            0.107650            0.017561   \n",
      "1       -0.10490       -0.10600            0.067851            0.029939   \n",
      "2       -0.10492       -0.10597            0.007275            0.028934   \n",
      "3       -0.10495       -0.10597           -0.013053            0.019448   \n",
      "4       -0.10495       -0.10596            0.005135            0.007652   \n",
      "\n",
      "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
      "0            0.000767               -0.74857                 2.1030   \n",
      "1            0.003386                0.33995                 1.5064   \n",
      "2           -0.005978               -0.26429                 1.5922   \n",
      "3           -0.008974                0.42684                 1.0993   \n",
      "4            0.005245               -0.50969                 1.4689   \n",
      "\n",
      "   linear_acceleration_Z  \n",
      "0                -9.7532  \n",
      "1                -9.4128  \n",
      "2                -8.7267  \n",
      "3               -10.0960  \n",
      "4               -10.4410  \n",
      "   series_id  group_id        surface\n",
      "0          0        13  fine_concrete\n",
      "1          1        31       concrete\n",
      "2          2        20       concrete\n",
      "3          3        31       concrete\n",
      "4          4        22     soft_tiles\n",
      "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
      "0    0_0          0                   0        0.91208       -0.38193   \n",
      "1    0_1          0                   1        0.91220       -0.38165   \n",
      "2    0_2          0                   2        0.91228       -0.38143   \n",
      "3    0_3          0                   3        0.91237       -0.38121   \n",
      "4    0_4          0                   4        0.91247       -0.38096   \n",
      "\n",
      "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
      "0      -0.050618        0.14028           -0.060205            0.071286   \n",
      "1      -0.050573        0.14028           -0.033486            0.060210   \n",
      "2      -0.050586        0.14032           -0.029686            0.029476   \n",
      "3      -0.050588        0.14035           -0.024217            0.037788   \n",
      "4      -0.050546        0.14042           -0.038047            0.083405   \n",
      "\n",
      "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
      "0            -0.18787                0.29492                 2.8027   \n",
      "1            -0.18206                0.14944                 2.5408   \n",
      "2            -0.18441               -0.49741                 2.5853   \n",
      "3            -0.18783               -0.32376                 2.9966   \n",
      "4            -0.20170               -0.70103                 2.6498   \n",
      "\n",
      "   linear_acceleration_Z  \n",
      "0                -9.6816  \n",
      "1                -9.8521  \n",
      "2                -9.3835  \n",
      "3                -8.7415  \n",
      "4                -8.8432  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Просмотр первых нескольких строк данных\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(X_test.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db8bd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Объединение данных X_train с y_train по столбцу 'series_id'\n",
    "train_data = X_train.merge(y_train, on='series_id')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87e7ae81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                   0\n",
       "series_id                0\n",
       "measurement_number       0\n",
       "orientation_X            0\n",
       "orientation_Y            0\n",
       "orientation_Z            0\n",
       "orientation_W            0\n",
       "angular_velocity_X       0\n",
       "angular_velocity_Y       0\n",
       "angular_velocity_Z       0\n",
       "linear_acceleration_X    0\n",
       "linear_acceleration_Y    0\n",
       "linear_acceleration_Z    0\n",
       "group_id                 0\n",
       "surface                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Проверка на пропущенные значения\n",
    "train_data.isnull().sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "233461ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Нормализация данных\n",
    "# # Нормализация данных\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Определим признаки, которые будут использованы для нормализации\n",
    "# features = [col for col in X_train.columns if col not in ['row_id', 'series_id', 'surface']]\n",
    "\n",
    "# # Применяем StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Обучаем scaler на тренировочных данных и трансформируем их\n",
    "# X_train_scaled = scaler.fit_transform(X_train[features])\n",
    "\n",
    "# # Применяем тот же scaler на тестовых данных (убедимся, что используем только те же самые столбцы)\n",
    "# X_test_scaled = scaler.transform(X_test[features])\n",
    "\n",
    "# # Целевые значения\n",
    "# # y_train_values = train_data['surface'].values\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(train_data['surface'])\n",
    "\n",
    "# # Нормализация данных\n",
    "# features = [col for col in X_train.columns if col not in ['row_id', 'series_id', 'surface']]\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_train[features])\n",
    "# X_test_scaled = scaler.transform(X_test[features])\n",
    "\n",
    "# # Разделение данных на обучающую и тестовую выборки\n",
    "# X_tr, X_te, y_tr, y_te = train_test_split(X_train_scaled, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Обучение модели\n",
    "# forest = RandomForest(n_estimators=10, max_depth=5)\n",
    "# forest.fit(X_tr, y_tr)\n",
    "\n",
    "# # Предсказание на тестовых данных\n",
    "# y_pred = forest.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "251208f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Разделение данных на обучающую и тестовую выборки\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_tr, X_te, y_tr, y_te = train_test_split(X_train_scaled, y_train_values, test_size=0.2, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "864b4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Реализация узла дерева решений\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad7a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Реализация дерева решений\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(np.unique(y))\n",
    "\n",
    "        if (depth >= self.max_depth or num_labels == 1 or num_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(num_features, num_features, replace=False)\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "\n",
    "        e_left, e_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "\n",
    "        ig = parent_entropy - child_entropy\n",
    "\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, threshold):\n",
    "        left_idxs = np.argwhere(X_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(X_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3a6b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Реализация случайного леса\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=10, min_samples_split=2):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        y_pred = [np.bincount(tree_pred.astype('int')).argmax() for tree_pred in tree_preds]\n",
    "        return np.array(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53768f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m     17\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForest(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mforest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Предсказание на тестовых данных\u001b[39;00m\n\u001b[1;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m forest\u001b[38;5;241m.\u001b[39mpredict(X_te)\n",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m, in \u001b[0;36mRandomForest.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m X_sample, y_sample \u001b[38;5;241m=\u001b[39m X[idxs], y[idxs]\n\u001b[1;32m     14\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTree(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[0;32mIn[34], line 9\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m, in \u001b[0;36mDecisionTree._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(value\u001b[38;5;241m=\u001b[39mleaf_value)\n\u001b[1;32m     19\u001b[0m feat_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(num_features, num_features, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m best_feat, best_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_best_criteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m left_idxs, right_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(X[:, best_feat], best_thresh)\n\u001b[1;32m     24\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X[left_idxs, :], y[left_idxs], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 38\u001b[0m, in \u001b[0;36mDecisionTree._best_criteria\u001b[0;34m(self, X, y, feat_idxs)\u001b[0m\n\u001b[1;32m     35\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(X_column)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m---> 38\u001b[0m     gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_information_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gain \u001b[38;5;241m>\u001b[39m best_gain:\n\u001b[1;32m     41\u001b[0m         best_gain \u001b[38;5;241m=\u001b[39m gain\n",
      "Cell \u001b[0;32mIn[34], line 49\u001b[0m, in \u001b[0;36mDecisionTree._information_gain\u001b[0;34m(self, y, X_column, threshold)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_information_gain\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, X_column, threshold):\n\u001b[1;32m     48\u001b[0m     parent_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entropy(y)\n\u001b[0;32m---> 49\u001b[0m     left_idxs, right_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_idxs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(right_idxs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[34], line 66\u001b[0m, in \u001b[0;36mDecisionTree._split\u001b[0;34m(self, X_column, threshold)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_column, threshold):\n\u001b[0;32m---> 66\u001b[0m     left_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     67\u001b[0m     right_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margwhere(X_column \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m left_idxs, right_idxs\n",
      "File \u001b[0;32m~/src/university/personal/machine-learning-basics/.conda/lib/python3.10/site-packages/numpy/core/numeric.py:608\u001b[0m, in \u001b[0;36margwhere\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;66;03m# then remove the added dimension\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argwhere(a)[:,:\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transpose(\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/src/university/personal/machine-learning-basics/.conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1973\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nonzero_dispatcher)\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnonzero\u001b[39m(a):\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    Return the indices of the elements that are non-zero.\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \n\u001b[1;32m   1972\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnonzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/university/personal/machine-learning-basics/.conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_data['surface'])\n",
    "\n",
    "# Нормализация данных\n",
    "features = [col for col in X_train.columns if col not in ['row_id', 'series_id', 'surface']]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train[features])\n",
    "X_test_scaled = scaler.transform(X_test[features])\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_train_scaled, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "forest = RandomForest(n_estimators=10, max_depth=10)\n",
    "forest.fit(X_tr, y_tr)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = forest.predict(X_te)\n",
    "# # Обучение модели\n",
    "# forest = RandomForest(n_estimators=10, max_depth=10)\n",
    "# forest.fit(X_tr, y_tr)\n",
    "\n",
    "# # Предсказание на тестовых данных\n",
    "# y_pred = forest.predict(X_te)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Оценка качества модели\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "accuracy = accuracy_score(y_te, y_pred)\n",
    "precision = precision_score(y_te, y_pred, average='macro')\n",
    "recall = recall_score(y_te, y_pred, average='macro')\n",
    "f1 = f1_score(y_te, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Построение ROC-кривой\n",
    "y_prob = np.mean([tree.predict(X_te) for tree in forest.trees], axis=0)\n",
    "fpr, tpr, thresholds = roc_curve(y_te, y_prob, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC кривая (площадь = {roc_auc:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ложноположительные')\n",
    "plt.ylabel('Истинно положительные')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ограничение глубины предотвращает переобучение, так как глубокие деревья могут \"запоминать\" тренировочные данные, плохо обобщая на новые. \n",
    "# Ограничение также уменьшает время обучения.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
