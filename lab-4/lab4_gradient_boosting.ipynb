{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4: Градиентный бустинг\n",
    "\n",
    "**Набор данных**: [Human Activity Recognition Using Smartphones](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)\n",
    "\n",
    "**Цель**: Реализовать градиентный бустинг с обоснованием выбора гиперпараметров, посчитать метрики качества (accuracy, precision, recall, F1-меру) и вывести ROC-кривую.\n",
    "\n",
    "**Примечание**: Использование библиотек типа scikit-learn, pytorch, tensorflow, keras запрещено. Разрешено использовать только вспомогательные библиотеки: pandas, numpy, matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contents",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "1. [Загрузка и предобработка данных](#data-loading)\n",
    "2. [Реализация градиентного бустинга](#gradient-boosting)\n",
    "   - [Классификатор Decision Stump](#decision-stump)\n",
    "   - [Классификатор Gradient Boosting](#gb-classifier)\n",
    "3. [Обоснование выбора гиперпараметров](#hyperparameters)\n",
    "4. [Обучение модели](#training)\n",
    "5. [Оценка модели](#evaluation)\n",
    "6. [Построение ROC-кривой](#roc-curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"data-loading\"></a>\n",
    "## 1. Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "data-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Загрузка набора данных\n",
    "# dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip'\n",
    "# urllib.request.urlretrieve(dataset_url, 'UCI_HAR_Dataset.zip')\n",
    "\n",
    "# # Распаковка набора данных\n",
    "# with zipfile.ZipFile('UCI_HAR_Dataset.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('UCI_HAR_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "data-loading-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138502/3961498569.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  X_train = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)\n",
      "/tmp/ipykernel_138502/3961498569.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y_train = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/train/y_train.txt', delim_whitespace=True, header=None)\n",
      "/tmp/ipykernel_138502/3961498569.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  X_test = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None)\n",
      "/tmp/ipykernel_138502/3961498569.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y_test = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/test/y_test.txt', delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка тренировочных данных\n",
    "X_train = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)\n",
    "y_train = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/train/y_train.txt', delim_whitespace=True, header=None)\n",
    "\n",
    "# Загрузка тестовых данных\n",
    "X_test = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None)\n",
    "y_test = pd.read_csv('UCI_HAR_Dataset/UCI HAR Dataset/test/y_test.txt', delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-preprocessing",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Для упрощения задачи сконцентрируемся на бинарной классификации, выбрав две активности: `1` (Walking) и `2` (Walking Upstairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "data-preprocessing-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация данных для классов 1 и 2\n",
    "binary_classes = [1, 2]\n",
    "train_filter = y_train[0].isin(binary_classes)\n",
    "test_filter = y_test[0].isin(binary_classes)\n",
    "\n",
    "X_train_binary = X_train[train_filter.values]\n",
    "y_train_binary = y_train[train_filter.values]\n",
    "X_test_binary = X_test[test_filter.values]\n",
    "y_test_binary = y_test[test_filter.values]\n",
    "\n",
    "# Преобразование меток в 0 и 1\n",
    "y_train_binary = y_train_binary[0].map({1: 0, 2: 1}).values\n",
    "y_test_binary = y_test_binary[0].map({1: 0, 2: 1}).values\n",
    "\n",
    "# Преобразование данных в numpy массивы\n",
    "X_train_binary = X_train_binary.values\n",
    "X_test_binary = X_test_binary.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient-boosting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"gradient-boosting\"></a>\n",
    "## 2. Реализация градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision-stump",
   "metadata": {},
   "source": [
    "<a name=\"decision-stump\"></a>\n",
    "### 2.1. Классификатор Decision Stump\n",
    "\n",
    "Реализуем простой решающий пень (Decision Stump), который будет использоваться в качестве базового алгоритма в градиентном бустинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decision-stump-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStumpRegressor:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left_value = None\n",
    "        self.right_value = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        min_error = float('inf')\n",
    "\n",
    "        # Перебор всех признаков\n",
    "        for feature_i in range(n_features):\n",
    "            feature_values = X[:, feature_i]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            # Перебор всех возможных порогов\n",
    "            for threshold in thresholds:\n",
    "                left_indices = feature_values < threshold\n",
    "                right_indices = feature_values >= threshold\n",
    "\n",
    "                # Вычисление средних значений для левого и правого узлов\n",
    "                left_mean = np.mean(y[left_indices]) if np.sum(left_indices) > 0 else 0\n",
    "                right_mean = np.mean(y[right_indices]) if np.sum(right_indices) > 0 else 0\n",
    "\n",
    "                # Вычисление ошибки\n",
    "                predictions = np.zeros(n_samples)\n",
    "                predictions[left_indices] = left_mean\n",
    "                predictions[right_indices] = right_mean\n",
    "                error = np.mean((y - predictions) ** 2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                    self.threshold = threshold\n",
    "                    self.feature_index = feature_i\n",
    "                    self.left_value = left_mean\n",
    "                    self.right_value = right_mean\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        feature_values = X[:, self.feature_index]\n",
    "        predictions = np.zeros(n_samples)\n",
    "        left_indices = feature_values < self.threshold\n",
    "        right_indices = feature_values >= self.threshold\n",
    "        predictions[left_indices] = self.left_value\n",
    "        predictions[right_indices] = self.right_value\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gb-classifier",
   "metadata": {},
   "source": [
    "<a name=\"gb-classifier\"></a>\n",
    "### 2.2. Классификатор Gradient Boosting\n",
    "\n",
    "Реализуем градиентный бустинг для бинарной классификации с использованием логистической функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gb-classifier-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.base_learners = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Инициализация прогнозов\n",
    "        y_pred = np.full(y.shape, np.log(np.sum(y == 1) / np.sum(y == 0)))\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Вычисление негативного градиента (остатков)\n",
    "            residual = y - self._sigmoid(y_pred)\n",
    "\n",
    "            # Обучение базового алгоритма на остатках\n",
    "            stump = DecisionStumpRegressor()\n",
    "            stump.fit(X, residual)\n",
    "\n",
    "            # Обновление прогнозов\n",
    "            y_pred += self.learning_rate * stump.predict(X)\n",
    "\n",
    "            # Сохранение базового алгоритма\n",
    "            self.base_learners.append(stump)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for stump in self.base_learners:\n",
    "            y_pred += self.learning_rate * stump.predict(X)\n",
    "        proba = self._sigmoid(y_pred)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameters",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"hyperparameters\"></a>\n",
    "## 3. Обоснование выбора гиперпараметров\n",
    "\n",
    "- **Количество базовых алгоритмов (n_estimators = 10)**: Выбрано для баланса между качеством модели и временем обучения. Большее число базовых алгоритмов может привести к переобучению и увеличению времени обучения.\n",
    "- **Скорость обучения (learning_rate = 0.1)**: Малое значение скорости обучения позволяет модели учиться более плавно и избегать переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"training\"></a>\n",
    "## 4. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051839fb-396a-4290-a3c5-b7a02c63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fraction = 0.20 \n",
    "binary_classes = [1, 2]\n",
    "train_filter = y_train[0].isin(binary_classes)\n",
    "test_filter = y_test[0].isin(binary_classes)\n",
    "\n",
    "X_train_binary = X_train[train_filter.values]\n",
    "y_train_binary = y_train[train_filter.values]\n",
    "X_test_binary = X_test[test_filter.values]\n",
    "y_test_binary = y_test[test_filter.values]\n",
    "\n",
    "\n",
    "y_train_binary = y_train_binary[0].map({1: 0, 2: 1})\n",
    "y_test_binary = y_test_binary[0].map({1: 0, 2: 1})\n",
    "\n",
    "\n",
    "train_sample = X_train_binary.sample(frac=sample_fraction, random_state=42)\n",
    "y_train_sample = y_train_binary.loc[train_sample.index]\n",
    "\n",
    "test_sample = X_test_binary.sample(frac=sample_fraction, random_state=42)\n",
    "y_test_sample = y_test_binary.loc[test_sample.index]\n",
    "\n",
    "\n",
    "X_train_sample = train_sample.values\n",
    "y_train_sample = y_train_sample.values\n",
    "X_test_sample = test_sample.values\n",
    "y_test_sample = y_test_sample.values\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1)\n",
    "gb_clf.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b062922-b190-477b-a077-afd618559361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9067\n",
      "Precision: 0.9175\n",
      "Recall: 0.8990\n",
      "F1 Score: 0.9082\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m y_scores \u001b[38;5;241m=\u001b[39m gb_clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_sample)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Вычисление ROC-кривой\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m fpr, tpr \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_roc_curve\u001b[49m(y_test_sample, y_scores)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Вычисление AUC\u001b[39;00m\n\u001b[1;32m     21\u001b[0m auc_value \u001b[38;5;241m=\u001b[39m compute_auc(fpr, tpr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = gb_clf.predict(X_test_sample)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_sample, y_pred)\n",
    "precision = precision_score(y_test_sample, y_pred)\n",
    "recall = recall_score(y_test_sample, y_pred)\n",
    "f1 = f1_score(y_test_sample, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "y_scores = gb_clf.predict_proba(X_test_sample)\n",
    "\n",
    "\n",
    "fpr, tpr = compute_roc_curve(y_test_sample, y_scores)\n",
    "\n",
    "\n",
    "auc_value = compute_auc(fpr, tpr)\n",
    "print(f'AUC: {auc_value:.4f}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_value:.4f})')\n",
    "plt.plot([0,1], [0,1], 'k--', label='Случайный классификатор')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация и обучение градиентного бустинга\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1)\n",
    "gb_clf.fit(X_train_binary, y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"evaluation\"></a>\n",
    "## 5. Оценка модели\n",
    "\n",
    "Реализуем функции для расчета метрик качества без использования scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metrics-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    predicted_positive = np.sum(y_pred == 1)\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    actual_positive = np.sum(y_true == 1)\n",
    "    return true_positive / actual_positive if actual_positive > 0 else 0\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "evaluation-code",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:159\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 69)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Прогноз на тестовых данных\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Расчет метрик\u001b[39;00m\n\u001b[1;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_binary, y_pred)\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 33\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stump \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_learners:\n\u001b[0;32m---> 28\u001b[0m     y_pred \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[43mstump\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(y_pred)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proba\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mDecisionStumpRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     39\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m     feature_values \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     41\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_samples)\n\u001b[1;32m     42\u001b[0m     left_indices \u001b[38;5;241m=\u001b[39m feature_values \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3814\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3814\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6058\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   6054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   6055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   6056\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   6057\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 6058\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 69)"
     ]
    }
   ],
   "source": [
    "# Прогноз на тестовых данных\n",
    "y_pred = gb_clf.predict(X_test_binary)\n",
    "\n",
    "# Расчет метрик\n",
    "accuracy = accuracy_score(y_test_binary, y_pred)\n",
    "precision = precision_score(y_test_binary, y_pred)\n",
    "recall = recall_score(y_test_binary, y_pred)\n",
    "f1 = f1_score(y_test_binary, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roc-curve",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"roc-curve\"></a>\n",
    "## 6. Построение ROC-кривой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_curve(y_true, y_scores):\n",
    "    thresholds = np.sort(np.unique(y_scores))\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "\n",
    "    P = np.sum(y_true == 1)\n",
    "    N = np.sum(y_true == 0)\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_scores >= thresh).astype(int)\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        TPR = TP / P if P > 0 else 0\n",
    "        FPR = FP / N if N > 0 else 0\n",
    "        tpr_list.append(TPR)\n",
    "        fpr_list.append(FPR)\n",
    "\n",
    "    return fpr_list, tpr_list\n",
    "\n",
    "def compute_auc(fpr, tpr):\n",
    "    sorted_indices = np.argsort(fpr)\n",
    "    fpr = np.array(fpr)[sorted_indices]\n",
    "    tpr = np.array(tpr)[sorted_indices]\n",
    "    return np.trapz(tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve-compute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение вероятностей\n",
    "y_scores = gb_clf.predict_proba(X_test_binary)\n",
    "\n",
    "# Вычисление ROC-кривой\n",
    "fpr, tpr = compute_roc_curve(y_test_binary, y_scores)\n",
    "\n",
    "# Вычисление AUC\n",
    "auc_value = compute_auc(fpr, tpr)\n",
    "print(f'AUC: {auc_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение ROC-кривой\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_value:.4f})')\n",
    "plt.plot([0,1], [0,1], 'k--', label='Случайный классификатор')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Вывод**: Мы успешно реализовали градиентный бустинг с использованием простых базовых алгоритмов (Decision Stump) и рассчитали метрики качества модели. ROC-кривая и AUC показывают качество работы модели на тестовых данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
